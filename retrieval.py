# ğŸ“ retrieval.py
from sklearn.preprocessing import normalize
import numpy as np
import faiss
from sklearn.neighbors import KNeighborsClassifier
from PIL import Image
import torch
import time
import matplotlib.pyplot as plt
import os
from utils import load_and_transform_image

# def build_faiss_index(train_features):
#     index = faiss.IndexFlatL2(train_features.shape[1])
#     index.add(train_features)
#     return index
def build_faiss_index(train_feats):
    """
    æ„å»º FAISS å†…ç§¯ç´¢å¼•ï¼ˆåŸºäº Cosine ç›¸ä¼¼åº¦ï¼‰ï¼Œå¹¶å¯¹ç‰¹å¾è¿›è¡Œ L2 å½’ä¸€åŒ–ã€‚
    """
    # âœ… ç‰¹å¾å½’ä¸€åŒ–ï¼ˆé‡è¦ï¼ï¼‰
    train_feats = normalize(train_feats, norm='l2')

    # âœ… ä½¿ç”¨å†…ç§¯ï¼ˆcosine similarityï¼‰ç´¢å¼•
    dim = train_feats.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(train_feats.astype('float32'))

    return index




def build_knn_classifier(train_features, train_labels, k=5):
    classifier = KNeighborsClassifier(n_neighbors=k)
    classifier.fit(train_features, train_labels)
    return classifier

def extract_features(loader, model, device, save_prefix):
    features, labels, paths = [], [], []
    total_batches = len(loader)

    with torch.no_grad():
        for batch_idx, (images, lbls) in enumerate(loader):
            images = images.to(device, non_blocking=True)
            feats = model(images)
            features.append(feats.cpu().numpy())
            labels.append(lbls.numpy())

            # âœ… æ­£ç¡®æ”¶é›†å›¾åƒè·¯å¾„ï¼ˆè¿™æ®µæ˜¯å…³é”®ï¼ï¼‰
            start_idx = batch_idx * loader.batch_size
            end_idx = start_idx + images.size(0)
            paths.extend(loader.dataset.samples[start_idx:end_idx])

            if (batch_idx + 1) % 10 == 0 or batch_idx == total_batches - 1:
                print(f"Processing batch {batch_idx+1}/{total_batches} for {save_prefix}")

    if features:
        np.save(f"{save_prefix}_features.npy", np.concatenate(features, axis=0))
        np.save(f"{save_prefix}_labels.npy", np.concatenate(labels, axis=0))
        np.save(f"{save_prefix}_paths.npy", np.array([p[0] for p in paths]))  # âœ… ä¿å­˜è·¯å¾„éƒ¨åˆ†

    features, labels,paths = [], [], []
    total_batches = len(loader)
    with torch.no_grad():
        for batch_idx, (images, lbls) in enumerate(loader):
            images = images.to(device, non_blocking=True)
            feats = model(images)
            features.append(feats.cpu().numpy())
            labels.append(lbls.numpy())
            # âœ… æ·»åŠ è·¯å¾„æ”¶é›†é€»è¾‘
            start_idx = batch_idx * loader.batch_size
            end_idx = start_idx + images.size(0)
            paths.extend(loader.dataset.samples[start_idx:end_idx])
            if (batch_idx + 1) % 10 == 0 or batch_idx == total_batches - 1:
                print(f"Processing batch {batch_idx+1}/{total_batches} for {save_prefix}")
    if features:
        np.save(f"{save_prefix}_features.npy", np.concatenate(features, axis=0))
        np.save(f"{save_prefix}_labels.npy", np.concatenate(labels, axis=0))
        np.save(f"{save_prefix}_paths.npy", np.array([p[0] for p in paths]))  # âœ… åªä¿ç•™è·¯å¾„éƒ¨åˆ†








def predict_and_search(image_path, model, knn, index, train_labels, train_data, transform, device, topk=5, save_visual=True):
    print(f"\nğŸ“¥ ä¸Šä¼ å›¾åƒè·¯å¾„: {image_path}")

    # âœ… ä¸€æ¬¡æ€§è·å– imageï¼ˆPILï¼‰ å’Œ image_tensorï¼ˆæ¨¡å‹è¾“å…¥ï¼‰
    image, image_tensor = load_and_transform_image(image_path, transform)
    image_tensor = image_tensor.unsqueeze(0).to(device)

    # âœ… ä¿å­˜ä¸Šä¼ å›¾åƒå‰¯æœ¬
    os.makedirs("retrieval_vis", exist_ok=True)
    upload_copy_path = os.path.join("retrieval_vis", "query_image.png")
    image.save(upload_copy_path)
    print(f"ğŸ“¸ å·²ä¿å­˜ä¸Šä¼ å›¾åƒå‰¯æœ¬åˆ°: {upload_copy_path}")

    # âœ… æ¨¡å‹æå–ç‰¹å¾ + åˆ†ç±» + æ£€ç´¢
    with torch.no_grad():
        feat = model(image_tensor).cpu().numpy()
        
# âœ… ä¿å­˜ query å›¾åƒçš„ç‰¹å¾å‘é‡ï¼Œç”¨äº Top-K å¯è§†åŒ–åˆ†æ
    np.save("query_feature.npy", feat)

    pred_label = knn.predict(feat)[0]
    print(f"\nâœ… é¢„æµ‹ç±»åˆ«: {'Normal' if pred_label == 0 else 'Pneumonia'}")

    start = time.time()
    distances, indices = index.search(feat.astype('float32'), topk)
    duration = time.time() - start
    print(f"â±ï¸ æ£€ç´¢è€—æ—¶: {duration:.4f} ç§’")

    print("\n===== Top-{} ç›¸ä¼¼å›¾åƒç»“æœ =====".format(topk))
    result_lines = [f"ğŸ“¥ ä¸Šä¼ å›¾åƒè·¯å¾„: {image_path}", f"âœ… é¢„æµ‹ç±»åˆ«: {'Normal' if pred_label == 0 else 'Pneumonia'}", ""]

    fig, axes = plt.subplots(1, topk, figsize=(topk * 3, 3)) if save_visual else (None, None)

    for i, idx in enumerate(indices[0]):
        label = train_labels[idx]
        path = train_data.samples[idx][0]
        result_line = f"Top-{i+1}: {path} | Label: {'Normal' if label == 0 else 'Pneumonia'} | Dist: {distances[0][i]:.4f}"
        result_lines.append(result_line)
        print(result_line)

        if save_visual:
            img = Image.open(path).convert('RGB')
            axes[i].imshow(img)
            axes[i].axis('off')
            axes[i].set_title(f"Top-{i+1}\n{'Normal' if label == 0 else 'Pneumonia'}")

    if save_visual:
        plt.tight_layout()
        plt.savefig("retrieval_vis/topk_result.png")
        plt.close()

    with open("retrieval_result.txt", "w", encoding="utf-8") as f:
        f.write("\n".join(result_lines))