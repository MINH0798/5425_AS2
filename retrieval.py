# ğŸ“ retrieval.py
from sklearn.preprocessing import normalize
import numpy as np
import faiss
from sklearn.neighbors import KNeighborsClassifier
from PIL import Image
import torch
import time
import matplotlib.pyplot as plt
import os
from utils import load_and_transform_image

# def build_faiss_index(train_features):
#     index = faiss.IndexFlatL2(train_features.shape[1])
#     index.add(train_features)
#     return index
def build_faiss_index(train_feats):
    """
    æ„å»º FAISS å†…ç§¯ç´¢å¼•ï¼ˆåŸºäº Cosine ç›¸ä¼¼åº¦ï¼‰ï¼Œå¹¶å¯¹ç‰¹å¾è¿›è¡Œ L2 å½’ä¸€åŒ–ã€‚
    """
    # âœ… ç‰¹å¾å½’ä¸€åŒ–ï¼ˆé‡è¦ï¼ï¼‰
    train_feats = normalize(train_feats, norm='l2')

    # âœ… ä½¿ç”¨å†…ç§¯ï¼ˆcosine similarityï¼‰ç´¢å¼•
    dim = train_feats.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(train_feats.astype('float32'))

    return index




def build_knn_classifier(train_features, train_labels, k=5):
    classifier = KNeighborsClassifier(n_neighbors=k)
    classifier.fit(train_features, train_labels)
    return classifier

def extract_features(loader, model, device, save_prefix):
    features, labels, paths = [], [], []
    total_batches = len(loader)

    with torch.no_grad():
        for batch_idx, (images, lbls) in enumerate(loader):
            images = images.to(device, non_blocking=True)
            feats = model(images)
            features.append(feats.cpu().numpy())
            labels.append(lbls.numpy())

            # âœ… æ­£ç¡®æ”¶é›†å›¾åƒè·¯å¾„ï¼ˆè¿™æ®µæ˜¯å…³é”®ï¼ï¼‰
            start_idx = batch_idx * loader.batch_size
            end_idx = start_idx + images.size(0)
            paths.extend(loader.dataset.samples[start_idx:end_idx])

            if (batch_idx + 1) % 10 == 0 or batch_idx == total_batches - 1:
                print(f"Processing batch {batch_idx+1}/{total_batches} for {save_prefix}")

    if features:
        os.makedirs("retrieval_vis", exist_ok=True)
        np.save(os.path.join("retrieval_vis", f"{save_prefix}_features.npy"), np.concatenate(features, axis=0))
        np.save(os.path.join("retrieval_vis", f"{save_prefix}_labels.npy"), np.concatenate(labels, axis=0))
        np.save(os.path.join("retrieval_vis", f"{save_prefix}_paths.npy"), np.array([p[0] for p in paths]))
    print(f"âœ… {save_prefix} features saved to 'retrieval_vis/'")  





def predict_and_search(image_path, model, knn, index, train_labels, train_data,
                       transform, device, topk=5, save_visual=True,
                       return_paths=False, return_details=False):
    print(f"\nğŸ“¥ ä¸Šä¼ å›¾åƒè·¯å¾„: {image_path}")

    # âœ… è¯»å–å’Œå¤„ç†å›¾åƒ
    image, image_tensor = load_and_transform_image(image_path, transform)
    image_tensor = image_tensor.unsqueeze(0).to(device)

    # âœ… ä¿å­˜ä¸Šä¼ å›¾åƒå‰¯æœ¬
    os.makedirs("retrieval_vis", exist_ok=True)
    upload_copy_path = os.path.join("retrieval_vis", "query_image.png")
    image.save(upload_copy_path)
    print(f"ğŸ“¸ å·²ä¿å­˜ä¸Šä¼ å›¾åƒå‰¯æœ¬åˆ°: {upload_copy_path}")

    # âœ… æå–ç‰¹å¾å¹¶ä¿å­˜
    with torch.no_grad():
        feat = model(image_tensor).cpu().numpy()

    np.save("retrieval_vis/query_feature.npy", feat)

    # âœ… KNN é¢„æµ‹ç±»åˆ«
    pred_label = knn.predict(feat)[0]
    print(f"\nâœ… é¢„æµ‹ç±»åˆ«: {'Normal' if pred_label == 0 else 'Pneumonia'}")

    # âœ… FAISS æ£€ç´¢
    start = time.time()
    distances, indices = index.search(feat.astype('float32'), topk)
    duration = time.time() - start
    print(f"â±ï¸ æ£€ç´¢è€—æ—¶: {duration:.4f} ç§’")

    print("\n===== Top-{} ç›¸ä¼¼å›¾åƒç»“æœ =====".format(topk))
    result_lines = [f"ğŸ“¥ ä¸Šä¼ å›¾åƒè·¯å¾„: {image_path}",
                    f"âœ… é¢„æµ‹ç±»åˆ«: {'Normal' if pred_label == 0 else 'Pneumonia'}",
                    f"â±ï¸ æ£€ç´¢è€—æ—¶: {duration:.4f} ç§’", ""]

    # âœ… åˆå§‹åŒ–è¿”å›å€¼åˆ—è¡¨
    topk_paths = []
    topk_labels = []
    topk_distances = []

    fig, axes = plt.subplots(1, topk, figsize=(topk * 3, 3)) if save_visual else (None, None)

    for i, idx in enumerate(indices[0]):
        label = train_labels[idx]
        path = train_data.samples[idx][0]
        label_str = 'Normal' if label == 0 else 'Pneumonia'
        dist = distances[0][i]

        topk_paths.append(path)
        topk_labels.append(label_str)
        topk_distances.append(dist)

        result_line = f"Top-{i+1}: {path} | Label: {label_str} | Dist: {dist:.4f}"
        result_lines.append(result_line)
        print(result_line)

        if save_visual:
            img = Image.open(path).convert('RGB')
            axes[i].imshow(img)
            axes[i].axis('off')
            axes[i].set_title(f"Top-{i+1}\n{label_str}")

    if save_visual:
        plt.tight_layout()
        plt.savefig("retrieval_vis/topk_result.png")
        plt.close()

    with open("retrieval_result.txt", "w", encoding="utf-8") as f:
        f.write("\n".join(result_lines))

    if return_paths and return_details:
        return list(zip(topk_paths, topk_labels, topk_distances)), pred_label
    elif return_paths:
        return topk_paths
    else:
        return
